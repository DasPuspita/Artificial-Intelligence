# -*- coding: utf-8 -*-
"""Copy of Copy of CSE422 Lab Project_Group 5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TW4eGf3_r2-4S2Ab16FmEy-G0a-G365f
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

df = pd.read_csv("/content/WineQT.csv")

df.head()

df.describe()

"""Data Preprocessing"""

# Check for null values
print(df.isnull().sum())

# Fill missing values for 'residual sugar' with mean
df['residual sugar'] = df['residual sugar'].fillna(df['residual sugar'].mean())

# Fill missing values for 'chlorides' with mean
df['chlorides'] = df['chlorides'].fillna(df['chlorides'].mean())

# Fill missing values for 'volatile acidity' with mean
df['volatile acidity'] = df['volatile acidity'].fillna(df['volatile acidity'].mean())

# Fill missing values for 'citric acid' with mean
df['citric acid'] = df['citric acid'].fillna(df['citric acid'].mean())

# Recheck null values
print(df.isnull().sum())

# Export cleaned dataset to new csv file
df.to_csv('WineQT_cleaned.csv', index=False)

df.head()

"""Scaling"""

# Load cleaned dataset
df = pd.read_csv('WineQT_cleaned.csv')

# List of numerical columns to scale
num_cols = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
            'chlorides', 'free sulfur dioxide', 'total sulfur dioxide',
            'density', 'pH', 'sulphates', 'alcohol']

# Create scaler object
scaler = MinMaxScaler()

# Scale numerical features
df[num_cols] = scaler.fit_transform(df[num_cols])

# Export scaled dataset to new file
df.to_csv('WineQT_scaled.csv', index=False)

correlations=df.corr()['quality'].drop('quality')
print(correlations)

sns.heatmap(df.corr())
plt.show()

def get_features(correlation_threshold):
  abs_corrs=correlations.abs()
  high_correlations = abs_corrs[abs_corrs> correlation_threshold].index.values.tolist()
  return high_correlations

features=get_features(0.05)
print(features)
x=df[features]
y=df['quality']

#x

#y

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=3)

"""Linear Regression Model"""

#fitting linear regression to training data
regressor = LinearRegression()
regressor.fit(x_train,y_train)

#this gives the coefficients of the 10 features selected above.
print(regressor.coef_)

train_pred = regressor.predict(x_train)
print(train_pred)

test_pred = regressor.predict(x_test)
print(test_pred)

train_rmse = metrics.mean_squared_error(train_pred,y_train)**0.5
print(train_rmse)

test_rmse = metrics.mean_squared_error(test_pred, y_test) ** 0.5
print(train_rmse)

# The root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample and population values) predicted by a model and the values actually observed.
# The RMSE for your training and your test sets should be very similar if you have built a good model.
# If the RMSE for the test set is much higher than that of the training set, it is likely that you've badly over fit the data

# rounding off the predicted values for test set
predicted_data = np.round_(test_pred)
predicted_data

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, test_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, test_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, test_pred)))

coeffecients = pd.DataFrame(regressor.coef_,features)
coeffecients.columns = ['Coeffecient']
print(coeffecients)
#These numbers mean that holding all other features fixed, a 1 unit increase in suplhates will lead to an increase of 0.8 in Quality of wine, and similarly for the other features
#These numbers mean that holding all other features fixed, a 1 unit increase in volatile acidity will lead to a decrease of 0.9

#Accuracy
regressor_accuracy = accuracy_score(y_test, predicted_data.round())*100
print("Linear Regression Accuracy: {:.2f}%".format(regressor_accuracy))

"""Ridge Regression Model"""

from sklearn.linear_model import Ridge
rid = Ridge()
print(rid.fit(x_train, y_train))

print(rid.coef_)

train_pred = rid.predict(x_train)
print(train_pred)

test_pred = rid.predict(x_test)
print(test_pred)

train_rmse = metrics.mean_squared_error(train_pred,y_train)**0.5
print(train_rmse)

test_rmse = metrics.mean_squared_error(test_pred, y_test) ** 0.5
print(train_rmse)

predicted_data = np.round_(test_pred)
predicted_data

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, test_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, test_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, test_pred)))

coeffecients = pd.DataFrame(rid.coef_,features)
coeffecients.columns = ['Coeffecient']
print(coeffecients)

#Accuracy
rid_accuracy = accuracy_score(y_test, predicted_data.round())*100
print("Ridge Regression Accuracy: {:.2f}%".format(rid_accuracy))